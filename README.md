# Generador de C√≥digo Terraform con LangChain y Hugging Face

Proyecto en Python que utiliza LangChain y modelos de Hugging Face para generar c√≥digo Terraform v√°lido a partir de descripciones en lenguaje natural. Incluye capacidad de entrenar modelos personalizados con tus propios datos.

## üìã Tabla de Contenidos

1. [Caracter√≠sticas](#caracter√≠sticas)
2. [Instalaci√≥n](#instalaci√≥n)
3. [Uso R√°pido](#uso-r√°pido)
4. [Entrenamiento del Modelo](#entrenamiento-del-modelo)
5. [Arquitectura y C√≥digo](#arquitectura-y-c√≥digo)
6. [Estructura del Proyecto](#estructura-del-proyecto)
7. [Soluci√≥n de Problemas](#soluci√≥n-de-problemas)
8. [Ejemplos Pr√°cticos](#ejemplos-pr√°cticos)

---

## ‚ú® Caracter√≠sticas

- **Generaci√≥n de c√≥digo Terraform**: Convierte descripciones en lenguaje natural a c√≥digo Terraform v√°lido
- **Modelos pre-entrenados**: Funciona inmediatamente con modelos de Hugging Face
- **Fine-tuning personalizado**: Entrena modelos con tus propios datos de Terraform
- **Validaci√≥n inteligente**: Filtra y valida c√≥digo generado autom√°ticamente
- **Interfaz flexible**: Modo interactivo, CLI y program√°tico
- **Soporte multi-recurso**: S3, EC2, EBS, Internet Gateway, KMS, y m√°s

---

## üöÄ Instalaci√≥n

### Requisitos Previos

- Python 3.8 o superior
- pip (gestor de paquetes de Python)
- Conexi√≥n a internet (para descargar modelos la primera vez)
- Opcional: GPU NVIDIA con CUDA (acelera entrenamiento y generaci√≥n)

### Instalaci√≥n Manual

1. **Clonar o descargar el proyecto**

2. **Crear entorno virtual (recomendado):**

   ```bash
   python -m venv venv
   # Windows
   venv\Scripts\activate
   # Linux/Mac
   source venv/bin/activate
   ```

3. **Instalar dependencias b√°sicas:**

   ```bash
   pip install python-dotenv sentencepiece "protobuf>=3.20.0,<5.0.0"
   ```

4. **Instalar ecosistema Hugging Face:**

   ```bash
   pip install "huggingface-hub>=0.16.0" "transformers>=4.30.0" "datasets>=2.12.0" "accelerate>=0.20.0"
   ```

5. **Instalar LangChain:**

   ```bash
   pip install "langchain>=0.1.0" "langchain-community>=0.0.10" "langchain-core>=0.1.0"
   ```

6. **Instalar PyTorch (seg√∫n tu sistema):**

   ```bash
   # Para CPU
   pip install torch

   # Para GPU NVIDIA (CUDA 11.8)
   pip install torch --index-url https://download.pytorch.org/whl/cu118

   # Para GPU NVIDIA (CUDA 12.1)
   pip install torch --index-url https://download.pytorch.org/whl/cu121
   ```

### Instalaci√≥n R√°pida (requirements.txt)

```bash
pip install -r requirements.txt
```

**Nota:** Si hay conflictos de dependencias, instala manualmente en el orden mostrado arriba.

### Verificar Instalaci√≥n

```bash
python -c "from terraform_generator import TerraformGenerator; print('‚úì Instalaci√≥n correcta')"
```

---

## ‚ö° Uso R√°pido

### 1. Probar con Modelo Pre-entrenado

**‚ö†Ô∏è Importante:** El modelo pre-entrenado NO est√° especializado en Terraform y puede generar c√≥digo de baja calidad o basura. Para mejores resultados, [entrena el modelo](#entrenamiento-del-modelo).

#### Modo Interactivo (Recomendado para principiantes):

```bash
python main.py
```

Luego ingresa descripciones como:

- "Crear un bucket S3 con versionado habilitado"
- "Crear una instancia EC2 tipo t2.micro"
- "Crear un volumen EBS de 20GB"

#### Desde l√≠nea de comandos:

```bash
python generate_terraform.py --prompt "Crear un bucket S3 con versionado habilitado"
```

#### Guardar c√≥digo en archivo:

```bash
python generate_terraform.py \
  --prompt "Crear un bucket S3" \
  --output s3_bucket.tf
```

#### Desde Python (program√°tico):

```python
from terraform_generator import TerraformGenerator

# Inicializar generador
generator = TerraformGenerator()

# Cargar modelo (se descarga autom√°ticamente la primera vez)
generator.load_model()

# Generar c√≥digo
codigo = generator.generate("Crear un bucket S3 con versionado")
print(codigo)
```

### 2. Usar Modelo Entrenado (Recomendado)

```bash
# Modo interactivo con modelo entrenado
python main.py --model_path models/terraform_generator

# Desde l√≠nea de comandos
python generate_terraform.py \
  --prompt "Crear una instancia EC2" \
  --model_path models/terraform_generator \
  --output ec2.tf
```

---

## üéì Entrenamiento del Modelo

### ¬øPor qu√© entrenar?

| Aspecto         | Modelo Pre-entrenado | Modelo Entrenado          |
| --------------- | -------------------- | ------------------------- |
| Calidad         | ‚ö†Ô∏è Variable/Basura   | ‚úÖ C√≥digo v√°lido          |
| Especializaci√≥n | ‚ùå No                | ‚úÖ S√≠, en Terraform       |
| Listo para usar | ‚úÖ Inmediato         | ‚è±Ô∏è Requiere entrenamiento |
| Tiempo          | 0 minutos            | 1-5 horas                 |

**El modelo pre-entrenado puede generar c√≥digo basura.** Para obtener c√≥digo Terraform de calidad, **debes entrenar el modelo** con tus datos.

### Paso 1: Preparar Datos de Entrenamiento

Los datos deben estar en `training_data/` con formato JSON:

```json
[
  {
    "description": "Crear un bucket S3 con versionado habilitado",
    "terraform_code": "resource \"aws_s3_bucket\" \"example\" {\n  bucket = \"my-bucket\"\n  versioning {\n    enabled = true\n  }\n}"
  },
  {
    "description": "Crear una instancia EC2 tipo t2.micro",
    "terraform_code": "resource \"aws_instance\" \"example\" {\n  ami           = \"ami-0c55b159cbfafe1f0\"\n  instance_type = \"t2.micro\"\n  tags = {\n    Name = \"example-instance\"\n  }\n}"
  }
]
```

**Ya tienes ejemplos en:**

- `training_data/example_training_data.json` - 5 ejemplos b√°sicos
- `training_data/expanded_training_data.json` - 56 ejemplos adicionales
- `training_data/additional_examples.json` - 93 ejemplos m√°s
- `training_data/internet_gateway_examples.json` - 3 ejemplos de Internet Gateway
- `training_data/kms_examples.json` - 6 ejemplos de KMS

**Total: 163 ejemplos listos para usar**

### Paso 2: Entrenar el Modelo

#### Entrenamiento b√°sico:

```bash
python train_model.py --data_dir training_data/ --output_dir models/terraform_generator
```

#### Entrenamiento con opciones avanzadas:

```bash
python train_model.py \
  --data_dir training_data/ \
  --output_dir models/terraform_generator \
  --epochs 5 \
  --batch_size 4 \
  --learning_rate 5e-5
```

#### Par√°metros de entrenamiento:

- `--data_dir`: Directorio con archivos de entrenamiento (default: `training_data`)
- `--output_dir`: Donde guardar el modelo entrenado (default: `models/terraform_generator`)
- `--epochs`: N√∫mero de √©pocas (default: 5, recomendado: 3-10)
- `--batch_size`: Tama√±o del batch (default: 4, ajustar seg√∫n RAM/GPU)
- `--learning_rate`: Tasa de aprendizaje (default: 5e-5, t√≠pico: 1e-5 a 5e-5)
- `--model_name`: Modelo base a usar (default: `microsoft/CodeGPT-small-py`)

**Tiempo estimado:**

- 5-10 ejemplos: 15-30 minutos (CPU)
- 50+ ejemplos: 1-3 horas (CPU) o 30-60 minutos (GPU)
- 100+ ejemplos: 3-5 horas (CPU) o 1-2 horas (GPU)

### Paso 3: Usar el Modelo Entrenado

```bash
# Modo interactivo
python main.py --model_path models/terraform_generator

# Desde l√≠nea de comandos
python generate_terraform.py \
  --prompt "Crear una instancia EC2" \
  --model_path models/terraform_generator \
  --output ec2.tf
```

### Verificar si Tienes Modelo Entrenado

```bash
# Windows
dir models\terraform_generator

# Linux/Mac
ls models/terraform_generator
```

Si la carpeta est√° vac√≠a o no existe, no tienes un modelo entrenado a√∫n.

---

## üèóÔ∏è Arquitectura y C√≥digo

### Componentes Principales

#### 1. `TerraformGenerator` (terraform_generator.py)

Clase principal que encapsula toda la l√≥gica de generaci√≥n:

```python
class TerraformGenerator:
    """
    Clase principal para generar c√≥digo Terraform usando modelos de Hugging Face.

    M√©todos principales:
    - __init__(): Inicializa el generador con configuraci√≥n
    - load_model(): Carga modelo pre-entrenado desde Hugging Face
    - load_from_local(): Carga modelo entrenado desde disco
    - train(): Entrena el modelo con datos personalizados
    - generate(): Genera c√≥digo Terraform desde descripci√≥n
    - generate_with_context(): Genera c√≥digo con contexto adicional
    """
```

**Flujo de generaci√≥n:**

1. **Carga del modelo**: Descarga o carga desde cach√©/disco
2. **Formateo del prompt**: A√±ade ejemplos few-shot y la descripci√≥n del usuario
3. **Generaci√≥n**: El modelo genera c√≥digo usando el pipeline de Hugging Face
4. **Limpieza**: Extrae solo el c√≥digo Terraform v√°lido
5. **Validaci√≥n**: Filtra c√≥digo inv√°lido y atributos incorrectos
6. **Retorno**: Devuelve c√≥digo limpio y v√°lido

**Sistema de validaci√≥n:**

El m√©todo `generate()` incluye validaci√≥n en m√∫ltiples niveles:

1. **Filtrado de patrones inv√°lidos:**

   - Recursos inexistentes: `aws_ebs_instance`, `aws_s3_instance`
   - Atributos inv√°lidos: `volume_name`, `instance_name`
   - C√≥digo basura: `TODO:`, `github.com`, `dongeran`
   - Markdown residual: ` ```terraform`, ` ``` `

2. **Validaci√≥n por tipo de recurso:**

   - `aws_internet_gateway`: Solo permite `vpc_id`, `tags`
   - `aws_s3_bucket`: Solo permite `bucket`, `tags`, `versioning`, etc.
   - `aws_instance`: Solo permite `ami`, `instance_type`, `tags`, etc.
   - `aws_ebs_volume`: Solo permite `availability_zone`, `size`, `type`, etc.
   - `aws_kms_key`: Solo permite `description`, `deletion_window_in_days`, etc.

3. **Validaci√≥n estructural:**
   - Verifica que haya un recurso v√°lido
   - Verifica que las llaves `{}` est√©n balanceadas
   - Extrae solo el primer recurso v√°lido encontrado

#### 2. Scripts de Interfaz

**`main.py`**: Interfaz interactiva

- Bucle continuo para m√∫ltiples generaciones
- Opci√≥n de guardar c√≥digo en archivos
- Manejo de errores amigable

**`generate_terraform.py`**: Interfaz CLI

- Ideal para automatizaci√≥n y scripts
- Soporta guardado directo en archivos
- Permite contexto adicional

**`train_model.py`**: Script de entrenamiento

- Carga datos desde m√∫ltiples archivos JSON/TXT
- Configura y ejecuta el entrenamiento
- Guarda checkpoints y modelo final

### Flujo de Entrenamiento

```
1. Cargar datos de entrenamiento
   ‚Üì
2. Formatear ejemplos con prompt template
   ‚Üì
3. Tokenizar datos usando el tokenizador del modelo
   ‚Üì
4. Configurar TrainingArguments
   ‚Üì
5. Crear Trainer con modelo, datos y collator
   ‚Üì
6. Ejecutar trainer.train()
   ‚Üì
7. Guardar modelo y tokenizador
```

### Prompt Engineering

El prompt template incluye:

1. **Instrucciones claras**: "Genera c√≥digo Terraform v√°lido y completo para AWS"
2. **Ejemplos few-shot**: 3 ejemplos de S3, EC2 y EBS
3. **Advertencias**: Lista de recursos y atributos inv√°lidos
4. **Formato**: Estructura consistente para el modelo

---

## üìÅ Estructura del Proyecto

```
.
‚îú‚îÄ‚îÄ main.py                      # Script interactivo principal
‚îú‚îÄ‚îÄ generate_terraform.py        # Generaci√≥n desde l√≠nea de comandos
‚îú‚îÄ‚îÄ train_model.py              # Script de entrenamiento
‚îú‚îÄ‚îÄ terraform_generator.py      # M√≥dulo principal con la l√≥gica
‚îú‚îÄ‚îÄ requirements.txt            # Dependencias del proyecto
‚îú‚îÄ‚îÄ README.md                   # Esta documentaci√≥n
‚îÇ
‚îú‚îÄ‚îÄ training_data/              # Datos de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ example_training_data.json      # 5 ejemplos b√°sicos
‚îÇ   ‚îú‚îÄ‚îÄ expanded_training_data.json     # 56 ejemplos adicionales
‚îÇ   ‚îú‚îÄ‚îÄ additional_examples.json        # 93 ejemplos m√°s
‚îÇ   ‚îú‚îÄ‚îÄ internet_gateway_examples.json  # 3 ejemplos de Internet Gateway
‚îÇ   ‚îî‚îÄ‚îÄ kms_examples.json               # 6 ejemplos de KMS
‚îÇ
‚îî‚îÄ‚îÄ models/                     # Modelos entrenados (se crea al entrenar)
    ‚îî‚îÄ‚îÄ terraform_generator/    # Modelo entrenado
        ‚îú‚îÄ‚îÄ model.safetensors   # Pesos del modelo
        ‚îú‚îÄ‚îÄ config.json         # Configuraci√≥n
        ‚îú‚îÄ‚îÄ tokenizer.json      # Tokenizador
        ‚îî‚îÄ‚îÄ ...                 # Otros archivos necesarios
```

---

## üîß Soluci√≥n de Problemas

### Error: "C√≥digo basura generado"

**Problema:** El modelo pre-entrenado genera c√≥digo inv√°lido como:

```
HAIL: dongeran la colonlas s3 en terraform """ # TODO: Fix this...
```

**Soluci√≥n:** Esto es normal con modelos pre-entrenados. **Entrena el modelo** con tus datos:

```bash
python train_model.py --data_dir training_data/ --output_dir models/terraform_generator
```

### Error: "Conflictos de dependencias"

**Soluci√≥n:** Instala manualmente en el orden correcto (ver [Instalaci√≥n](#instalaci√≥n)) o usa versiones compatibles:

```bash
pip install --upgrade pip
pip install "langchain>=0.1.0" "langchain-community>=0.0.10" "langchain-core>=0.1.0"
```

### Error: "Modelo no encontrado"

- Los modelos se descargan autom√°ticamente la primera vez
- Verifica tu conexi√≥n a internet
- Algunos modelos pueden requerir autenticaci√≥n en Hugging Face
- Verifica que el nombre del modelo sea correcto

### Error: "Out of memory"

- Usa un modelo m√°s peque√±o: `--model_name gpt2`
- Reduce batch_size: `--batch_size 2`
- Cierra otras aplicaciones
- Usa CPU si no tienes suficiente VRAM en GPU

### Generaci√≥n lenta

- El primer uso es m√°s lento (descarga del modelo)
- Considera usar GPU si est√° disponible
- Los modelos entrenados son m√°s r√°pidos que los pre-entrenados
- Reduce `max_length` si no necesitas c√≥digo muy largo

### Warnings sobre bitsandbytes/torch

Son normales si no tienes GPU. No afectan la funcionalidad, el proyecto funciona perfectamente en CPU.

### Error: "TrainingArguments.**init**() got an unexpected keyword argument 'evaluation_strategy'"

**Soluci√≥n:** Actualiza transformers:

```bash
pip install --upgrade transformers
```

El c√≥digo ya incluye un fallback para versiones antiguas, pero es mejor actualizar.

---

## üìù Ejemplos Pr√°cticos

### Generar y Guardar C√≥digo

```bash
python generate_terraform.py \
  --prompt "Crear un bucket S3 con encriptaci√≥n" \
  --output s3_bucket.tf
```

### Generar con Contexto

```bash
python generate_terraform.py \
  --prompt "Crear un grupo de seguridad" \
  --context "Para una instancia EC2 en la VPC vpc-12345"
```

### Entrenar con Par√°metros Personalizados

```bash
python train_model.py \
  --data_dir training_data/ \
  --output_dir models/terraform_generator \
  --epochs 10 \
  --batch_size 8 \
  --learning_rate 3e-5
```

### Uso Program√°tico

```python
from terraform_generator import TerraformGenerator

# Inicializar
generator = TerraformGenerator(
    model_name="microsoft/CodeGPT-small-py",
    temperature=0.3,
    max_length=512
)

# Cargar modelo entrenado
generator.load_from_local("models/terraform_generator")

# Generar c√≥digo
codigo = generator.generate("Crear un bucket S3 con versionado")

# Generar con contexto
codigo = generator.generate_with_context(
    "Crear un grupo de seguridad",
    "Para una instancia EC2 en la VPC vpc-12345"
)

print(codigo)
```

---

## üéØ Modelos Soportados

Por defecto se usa:

- `microsoft/CodeGPT-small-py` (pre-entrenado, especializado en Python pero adaptable)
- `gpt2` (para pruebas r√°pidas, m√°s peque√±o)

Puedes especificar otros modelos:

```bash
python main.py --model_name "Salesforce/codegen-350M-mono"
python train_model.py --model_name "gpt2" --data_dir training_data/
```

**Recomendaciones:**

- Para entrenamiento: Usa modelos peque√±os como `gpt2` o `microsoft/CodeGPT-small-py`
- Para producci√≥n: Entrena primero con tus datos, luego usa el modelo entrenado
- Para pruebas: `gpt2` es r√°pido pero menos preciso

---

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Variables de Entorno

Crear archivo `.env`:

```
HUGGINGFACE_API_TOKEN=tu_token_aqui
```

### Personalizar Par√°metros en C√≥digo

En `terraform_generator.py` puedes ajustar:

```python
generator = TerraformGenerator(
    model_name="microsoft/CodeGPT-small-py",
    device="auto",           # "cpu", "cuda", o "auto"
    max_length=512,           # Longitud m√°xima de secuencia
    temperature=0.7           # Creatividad (0.1-1.0)
)
```

### Ajustar Validaci√≥n

En el m√©todo `generate()` de `terraform_generator.py`, puedes modificar:

- `invalid_patterns`: Lista de patrones a filtrar
- `resource_attr_validation`: Validaci√≥n por tipo de recurso
- L√≥gica de extracci√≥n de c√≥digo v√°lido

---

## üìö Pr√≥ximos Pasos

1. ‚úÖ **Probar** con modelo pre-entrenado: `python main.py`
2. üìä **Agregar m√°s datos** de entrenamiento en `training_data/`
3. üéì **Entrenar el modelo**: `python train_model.py --data_dir training_data/ --output_dir models/terraform_generator`
4. üöÄ **Usar modelo entrenado**: `python main.py --model_path models/terraform_generator`
5. üîß **Personalizar**: Ajusta par√°metros seg√∫n tus necesidades

---

## ‚ö†Ô∏è Notas Importantes

- **Primera ejecuci√≥n:** Los modelos se descargan autom√°ticamente (puede tomar varios minutos)
- **Recursos:** El entrenamiento requiere recursos computacionales significativos
- **GPU:** Opcional pero recomendado para entrenamiento y modelos grandes
- **Datos:** Mientras m√°s ejemplos de entrenamiento tengas, mejor ser√° el modelo
- **Calidad:** El modelo pre-entrenado nunca ser√° tan bueno como uno entrenado espec√≠ficamente para Terraform
- **Validaci√≥n:** El sistema de validaci√≥n es agresivo para asegurar c√≥digo v√°lido, pero puede rechazar c√≥digo v√°lido en casos edge

---

## üìÑ Licencia

Este proyecto es de c√≥digo abierto. Si√©ntete libre de usarlo y modificarlo seg√∫n tus necesidades.

---

## ü§ù Contribuciones

Las contribuciones son bienvenidas. Algunas ideas:

- Agregar m√°s ejemplos de entrenamiento
- Mejorar la validaci√≥n de c√≥digo
- Agregar soporte para m√°s recursos de AWS
- Optimizar el rendimiento

---

**¬øNecesitas ayuda?** Revisa la secci√≥n [Soluci√≥n de Problemas](#soluci√≥n-de-problemas) o consulta los comentarios detallados en el c√≥digo fuente.
